{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Step 2: Define Folder Paths\n",
    "POS = '/content/drive/MyDrive/audio/data/Parsed_Violence_Clips'\n",
    "NEG = '/content/drive/MyDrive/audio/data/Parsed_Not_Violence_Clips'\n",
    "\n",
    "# Step 3: Install TensorFlow and TensorFlow I/O\n",
    "%pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 matplotlib\n",
    "%pip install tensorflow-io\n",
    "\n",
    "# Step 4: Import Necessary Libraries and Define the Data Loading Function\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    # Load the file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode the WAV file\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Resample to 16kHz\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=1600)0\n",
    "    return wav\n",
    "\n",
    "# Step 5: Define Paths to Files and Plot Waves\n",
    "VIOLENT_FILE = os.path.join(POS, 'XC3776-3.wav')\n",
    "NOT_VIOLENT_FILE = os.path.join(NEG, 'CVBD8.wav')\n",
    "\n",
    "wave = load_wav_16k_mono(VIOLENT_FILE)\n",
    "nwave = load_wav_16k_mono(NOT_VIOLENT_FIL)E\n",
    "plt.plot(wave)\n",
    "plt.plot(nwave)\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Create TensorFlow Dataset\n",
    "pos = tf.data.Dataset.list_files(os.path.join(POS, '*.wav'))\n",
    "neg = tf.data.Dataset.list_files(os.path.join(NEG, '*.wav'))\n",
    "\n",
    "# Step 7: Add labels and Combine Positive and Negative Samples\n",
    "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
    "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
    "data = positives.concatenate(negatives)\n",
    "\n",
    "# Step 8: Determine Average Length of a Capuchin Call\n",
    "lengths = []\n",
    "\n",
    "for file in os.listdir(POS):\n",
    "    tensor_wave = load_wav_16k_mono(os.path.join(POS, file))\n",
    "    lengths.append(len(tensor_wave))\n",
    "\n",
    "mean_length = tf.math.reduce_mean(lengths)\n",
    "min_length = tf.math.reduce_min(lengths)\n",
    "max_length = tf.math.reduce_max(lengths)\n",
    "\n",
    "print(f\"Mean Length: {mean_length}\")\n",
    "print(f\"Min Length: {min_length}\")\n",
    "print(f\"Max Length: {max_length}\")\n",
    "\n",
    "# Step 9: Build Preprocessing Function to Convert to Spectrogram\n",
    "def preprocess(file_path, label):\n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    wav = wav[:48000]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    # Ensure the spectrogram has a fixed shape\n",
    "    spectrogram.set_shape([1491, 257, 1])  # Set the shape explicitly\n",
    "    return spectrogram, label\n",
    "\n",
    "# Step 10: Test Out the Function and Viz the Spectrogram\n",
    "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()\n",
    "spectrogram, label = preprocess(filepath, label)\n",
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(tf.transpose(spectrogram)[0])\n",
    "plt.show()\n",
    "\n",
    "# Step 11: Create Training and Testing Partitions\n",
    "data = data.map(preprocess)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "data = data.batch(16)\n",
    "data = data.prefetch(8)\n",
    "\n",
    "train = data.take(36)\n",
    "test = data.skip(36).take(15)\n",
    "\n",
    "samples, labels = train.as_numpy_iterator().next()\n",
    "samples.shape\n",
    "\n",
    "# Step 12: Build Deep Learning Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(train, epochs=4, validation_data=test)\n",
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()\n",
    "plt.title('Precision')\n",
    "plt.plot(hist.history['precision'], 'r')\n",
    "plt.plot(hist.history['val_precision'], 'b')\n",
    "plt.show()\n",
    "plt.title('Recall')\n",
    "plt.plot(hist.history['recall'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.show()\n",
    "\n",
    "# Step 13: Make a Prediction on a Single Clip\n",
    "X_test, y_test = test.as_numpy_iterator().next()\n",
    "yhat = model.predict(X_test)\n",
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]\n",
    "\n",
    "# Step 14: Build Forest Parsing Functions\n",
    "def load_mp3_16k_mono(filename):\n",
    "    res = tfio.audio.AudioIOTensor(filename)\n",
    "    tensor = res.to_tensor()\n",
    "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2\n",
    "    sample_rate = res.rate\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "mp3 = os.path.join('data', 'Environment Recordings', 'recording_00.mp3')\n",
    "wav = load_mp3_16k_mono(mp3)\n",
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
    "samples, index = audio_slices.as_numpy_iterator().next()\n",
    "## 9.2 Build Function to Convert Clips into Windowed Spectrograms\n",
    "def preprocess_mp3(sample, index):\n",
    "    sample = sample[0]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, sample],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram\n",
    "## 9.3 Convert Longer Clips into Windows and Make Predictions\n",
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)\n",
    "audio_slices = audio_slices.map(preprocess_mp3)\n",
    "audio_slices = audio_slices.batch(64)\n",
    "yhat = model.predict(audio_slices)\n",
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]\n",
    "## 9.4 Group Consecutive Detections\n",
    "from itertools import groupby\n",
    "yhat = [key for key, group in groupby(yhat)]\n",
    "calls = tf.math.reduce_sum(yhat).numpy()\n",
    "calls\n",
    "# 10. Make Predictions\n",
    "## 10.1 Loop over all recordings and make predictions\n",
    "results = {}\n",
    "for file in os.listdir(os.path.join('data', 'Environment Recordings')):\n",
    "    FILEPATH = os.path.join('data','Environment Recordings', file)\n",
    "\n",
    "    wav = load_mp3_16k_mono(FILEPATH)\n",
    "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
    "    audio_slices = audio_slices.map(preprocess_mp3)\n",
    "    audio_slices = audio_slices.batch(64)\n",
    "\n",
    "    yhat = model.predict(audio_slices)\n",
    "\n",
    "    results[file] = yhat\n",
    "results\n",
    "## 10.2 Convert Predictions into Classes\n",
    "class_preds = {}\n",
    "for file, logits in results.items():\n",
    "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]\n",
    "class_preds\n",
    "## 10.3 Group Consecutive Detections\n",
    "postprocessed = {}\n",
    "for file, scores in class_preds.items():\n",
    "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
    "postprocessed\n",
    "# 11. Export Results\n",
    "import csv\n",
    "with open('results.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(['recording', 'violence_calls'])\n",
    "    for key, value in postprocessed.items():\n",
    "        writer.writerow([key, value])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
